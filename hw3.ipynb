{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[{"file_id":"1ZiHvyOxioMH9agky0FJGpwVn2yrf1cAo","timestamp":1712591024059}]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"40c953e50bea4456b3636ec468b32f14":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c9f6dda2f6c743f8b5e097ef9c37bbb2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1adcd5d7b2d64095b7f4009206843375","IPY_MODEL_50fdf3a8769e4e088045397cf582f24e","IPY_MODEL_bccc745f50c44be481e792082dc56bdc"]}},"c9f6dda2f6c743f8b5e097ef9c37bbb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1adcd5d7b2d64095b7f4009206843375":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3a0761a5580441afa603aae4a9f940f5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8080593c6cca4c54ac01a5346a400469"}},"50fdf3a8769e4e088045397cf582f24e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d1428b9747444a5795ee4ab454f2d561","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":155,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":155,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2568e2a9a63940a1afc4bf99297f43c5"}},"bccc745f50c44be481e792082dc56bdc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_498da906503141ffabdbd3406d008523","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 155/155 [02:08&lt;00:00,  1.61it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e57e20ff9025496692f9e38184d83221"}},"3a0761a5580441afa603aae4a9f940f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8080593c6cca4c54ac01a5346a400469":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1428b9747444a5795ee4ab454f2d561":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2568e2a9a63940a1afc4bf99297f43c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"498da906503141ffabdbd3406d008523":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e57e20ff9025496692f9e38184d83221":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21df1b0c3af1404db71f92815ce4f7e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cc6cfc6957df4777a60c22518a513add","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5705c9836e6744798ebf26e082624ad6","IPY_MODEL_7b2f9765b52140949f5107490b1a19cf","IPY_MODEL_87a51e79aefe4d37aa4a61d2537eb164"]}},"cc6cfc6957df4777a60c22518a513add":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5705c9836e6744798ebf26e082624ad6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8b757d6eb91b4fed8a23bf1f41a7cfd2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_455f6d586b094606a36ed3dd967102c9"}},"7b2f9765b52140949f5107490b1a19cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2f9c9c8c00f145778e35bacaa59a8b5e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":54,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":54,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bf326d803d0c43a6ad27b6ade626af7e"}},"87a51e79aefe4d37aa4a61d2537eb164":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0193eae66b6d44d98c8c7af1c3ca245e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 54/54 [00:33&lt;00:00,  2.08it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94e8fcba033a4d6d8be5c31f8435427c"}},"8b757d6eb91b4fed8a23bf1f41a7cfd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"455f6d586b094606a36ed3dd967102c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f9c9c8c00f145778e35bacaa59a8b5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bf326d803d0c43a6ad27b6ade626af7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0193eae66b6d44d98c8c7af1c3ca245e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"94e8fcba033a4d6d8be5c31f8435427c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5a7f7e01edbf4429a4adc7ced4304fca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_112b45da977a43be81589781387fcb25","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_34b9d75cfa3e4e5ebde73f84a233c7c9","IPY_MODEL_c59c72e2c7f04b549a45f2267cbb94fe","IPY_MODEL_3eb723e514bf410997e58e12b2aa9870"]}},"112b45da977a43be81589781387fcb25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"34b9d75cfa3e4e5ebde73f84a233c7c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_01f202ceca4c432fb25cf1adceadddd4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_606cca0455f941a0873c1af403505a7c"}},"c59c72e2c7f04b549a45f2267cbb94fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ff674b6f3a484cf683bfe5385d798c3c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":155,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":155,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f829df6953e740a19edfaa52f7ef9571"}},"3eb723e514bf410997e58e12b2aa9870":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4157cbb8f5b7489683669b25b583b324","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 155/155 [02:07&lt;00:00,  1.57it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d246b05af2e440eb1eb46ee1f3685b3"}},"01f202ceca4c432fb25cf1adceadddd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"606cca0455f941a0873c1af403505a7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ff674b6f3a484cf683bfe5385d798c3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f829df6953e740a19edfaa52f7ef9571":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4157cbb8f5b7489683669b25b583b324":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5d246b05af2e440eb1eb46ee1f3685b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c894a6d22ca84dcd87a7b54557b9ef03":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_20bffe91f7b7419f97fdcbf8802002b2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7d6f69caa40146798c57e9d07c946203","IPY_MODEL_60d2c08bdb7648a984770c04f709fe0e","IPY_MODEL_0b319f5705bf4c1f88e7ff53951d7486"]}},"20bffe91f7b7419f97fdcbf8802002b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d6f69caa40146798c57e9d07c946203":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a2964dbea2e2484c9a6b41f7c732071b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_002050c9657448f3836ddeb14757026f"}},"60d2c08bdb7648a984770c04f709fe0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d1785aa220e54739b611cc3ec832bb92","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":54,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":54,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4392f8b04afa43d387fb6338577c889d"}},"0b319f5705bf4c1f88e7ff53951d7486":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_940659b9b3c74d0c99d170abf6b4c22f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 54/54 [00:33&lt;00:00,  1.70it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a40ef0d028874f328aa2bfa36af5c1f9"}},"a2964dbea2e2484c9a6b41f7c732071b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"002050c9657448f3836ddeb14757026f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1785aa220e54739b611cc3ec832bb92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4392f8b04afa43d387fb6338577c889d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"940659b9b3c74d0c99d170abf6b4c22f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a40ef0d028874f328aa2bfa36af5c1f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"669ca3f9058a41b991203298f4046b26":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_be043829292e4029bbcbc4bbf68634a6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2ce21509b5254cd082ddbaeab13481fa","IPY_MODEL_61ed9e0c1a7949b7bb916c0ab5b9be39","IPY_MODEL_1419c935e12a43c6ad282126e220b04f"]}},"be043829292e4029bbcbc4bbf68634a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ce21509b5254cd082ddbaeab13481fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_05620cbadedf4d6ea05468ed8fe174bb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3410d1eb883e4676b83f736a0b3c7ac0"}},"61ed9e0c1a7949b7bb916c0ab5b9be39":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_082f25ab850d4935b0843b0726e4db86","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":155,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":155,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e6ed1370acc4a6192a6977311d4fefe"}},"1419c935e12a43c6ad282126e220b04f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0ce96c05d8b7417ea552b7a0a5db757f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 155/155 [02:08&lt;00:00,  1.52it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_51fc23b7d9e54434aabb27a0fdbdb0ef"}},"05620cbadedf4d6ea05468ed8fe174bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3410d1eb883e4676b83f736a0b3c7ac0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"082f25ab850d4935b0843b0726e4db86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1e6ed1370acc4a6192a6977311d4fefe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ce96c05d8b7417ea552b7a0a5db757f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"51fc23b7d9e54434aabb27a0fdbdb0ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa9cd7d0ffb2405c9cb1756644a59752":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_629f28ab51254b83b47ad07ead1f6827","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5ac6bf2dbe224a078c2e3fa349e0ae6e","IPY_MODEL_4b7d4d1dadd44039bbe954ff12f5421c","IPY_MODEL_fa9320b10cbb4448a63526be9492c4c7"]}},"629f28ab51254b83b47ad07ead1f6827":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ac6bf2dbe224a078c2e3fa349e0ae6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7555c0cdbb3c4bc78281d0ce30b6d50a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_37cb05e865ae4e93aeae6dcadc516a32"}},"4b7d4d1dadd44039bbe954ff12f5421c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e081dbdcd04547489bcf374e22a343cc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":54,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":54,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ea92a75640ba4b0da70c1592f555b006"}},"fa9320b10cbb4448a63526be9492c4c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3e728be5faf84b7d9c1eea54547938c1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 54/54 [00:33&lt;00:00,  1.96it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7c3ffac62aa04f568b90499734bf725b"}},"7555c0cdbb3c4bc78281d0ce30b6d50a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"37cb05e865ae4e93aeae6dcadc516a32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e081dbdcd04547489bcf374e22a343cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ea92a75640ba4b0da70c1592f555b006":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e728be5faf84b7d9c1eea54547938c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7c3ffac62aa04f568b90499734bf725b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":34954,"databundleVersionId":3300998,"sourceType":"competition"}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# HW3 Image Classification\n## We strongly recommend that you run with Kaggle for this homework\nhttps://www.kaggle.com/c/ml2022spring-hw3b/code?competitionId=34954&sortBy=dateCreated","metadata":{"id":"jRDuJsGCgxCO"}},{"cell_type":"markdown","source":"# Get Data\nNotes: if the links are dead, you can download the data directly from Kaggle and upload it to the workspace, or you can use the Kaggle API to directly download the data into colab.\n","metadata":{"id":"EVgrPb3HhJUT"}},{"cell_type":"code","source":"# cd","metadata":{"execution":{"iopub.status.busy":"2024-04-25T13:24:07.216425Z","iopub.execute_input":"2024-04-25T13:24:07.216777Z","iopub.status.idle":"2024-04-25T13:24:07.221159Z","shell.execute_reply.started":"2024-04-25T13:24:07.216748Z","shell.execute_reply":"2024-04-25T13:24:07.220097Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# ! wget https://www.dropbox.com/s/6l2vcvxl54b0b6w/food11.zip","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":19.351342,"end_time":"2022-02-23T10:03:06.247288","exception":false,"start_time":"2022-02-23T10:02:46.895946","status":"completed"},"tags":[],"id":"EAO6dg9eVaU_","outputId":"6ab4a9f9-8dd6-4259-8d1e-1215e6521486","execution":{"iopub.status.busy":"2024-04-25T13:24:07.223067Z","iopub.execute_input":"2024-04-25T13:24:07.223355Z","iopub.status.idle":"2024-04-25T13:24:07.230353Z","shell.execute_reply.started":"2024-04-25T13:24:07.223330Z","shell.execute_reply":"2024-04-25T13:24:07.229285Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# ! unzip food11.zip","metadata":{"execution":{"iopub.status.busy":"2024-04-25T13:24:07.231742Z","iopub.execute_input":"2024-04-25T13:24:07.232092Z","iopub.status.idle":"2024-04-25T13:24:07.239264Z","shell.execute_reply.started":"2024-04-25T13:24:07.232046Z","shell.execute_reply":"2024-04-25T13:24:07.238357Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"n5ceUnRihL-f"}},{"cell_type":"code","source":"_exp_name = \"sample\"","metadata":{"papermill":{"duration":0.0189,"end_time":"2022-02-23T10:03:06.279758","exception":false,"start_time":"2022-02-23T10:03:06.260858","status":"completed"},"tags":[],"id":"ay3WkYnHVaVE","execution":{"iopub.status.busy":"2024-04-25T13:24:07.241567Z","iopub.execute_input":"2024-04-25T13:24:07.241870Z","iopub.status.idle":"2024-04-25T13:24:07.248398Z","shell.execute_reply.started":"2024-04-25T13:24:07.241846Z","shell.execute_reply":"2024-04-25T13:24:07.247521Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Import necessary packages.\nimport numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\n# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\nfrom torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\nfrom torchvision.datasets import DatasetFolder, VisionDataset\n\n# This is for the progress bar.\nfrom tqdm.auto import tqdm\nimport random\nfrom sklearn.model_selection import KFold","metadata":{"papermill":{"duration":1.654263,"end_time":"2022-02-23T10:03:07.947242","exception":false,"start_time":"2022-02-23T10:03:06.292979","status":"completed"},"tags":[],"id":"CwOGtRWHVaVF","execution":{"iopub.status.busy":"2024-04-25T13:24:07.249420Z","iopub.execute_input":"2024-04-25T13:24:07.249713Z","iopub.status.idle":"2024-04-25T13:24:17.187774Z","shell.execute_reply.started":"2024-04-25T13:24:07.249689Z","shell.execute_reply":"2024-04-25T13:24:17.186718Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"myseed = 6666  # set a random seed for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(myseed)\ntorch.manual_seed(myseed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(myseed)","metadata":{"papermill":{"duration":0.078771,"end_time":"2022-02-23T10:03:08.039428","exception":false,"start_time":"2022-02-23T10:03:07.960657","status":"completed"},"tags":[],"id":"8kJm9GekVaVH","execution":{"iopub.status.busy":"2024-04-25T13:24:17.189126Z","iopub.execute_input":"2024-04-25T13:24:17.189694Z","iopub.status.idle":"2024-04-25T13:24:17.254933Z","shell.execute_reply.started":"2024-04-25T13:24:17.189656Z","shell.execute_reply":"2024-04-25T13:24:17.253878Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## **Transforms**\nTorchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.\n\nPlease refer to PyTorch official website for details about different transforms.","metadata":{"papermill":{"duration":0.01289,"end_time":"2022-02-23T10:03:08.065357","exception":false,"start_time":"2022-02-23T10:03:08.052467","status":"completed"},"tags":[],"id":"d9MVtgbSVaVH"}},{"cell_type":"code","source":"# Normally, We don't need augmentations in testing and validation.\n# All we need here is to resize the PIL image and transform it into Tensor.\ntest_tfm = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n])\n\n# However, it is also possible to use augmentation in the testing phase.\n# You may use train_tfm to produce a variety of images and then test using ensemble methods\n# train_tfm = transforms.Compose([\n#     # Resize the image into a fixed shape (height = width = 128)\n#     transforms.Resize((128, 128)),\n#     # You may add some transforms here.\n#     # ToTensor() should be the last one of the transforms.\n#     transforms.ToTensor(),\n# ])\n\n# 变换相关的网站：https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py\ntrain_tfm2 = transforms.Compose([\n    # Resize the image into a fixed shape (height = width = 128)\n    transforms.Resize((128, 128)),\n    # You may add some transforms here.\n    # 这个变换可以去一些地方找一些新方法\n    transforms.RandomChoice(transforms=[\n        # Apply TrivialAugmentWide data augmentation method\n        transforms.TrivialAugmentWide(),\n        # Return original image\n        transforms.Lambda(lambda x: x),\n    ],p=[0.95, 0.05]),\n\n    # ToTensor() should be the last one of the transfo·rms.\n    transforms.ToTensor(),\n])\n","metadata":{"papermill":{"duration":0.021406,"end_time":"2022-02-23T10:03:08.099437","exception":false,"start_time":"2022-02-23T10:03:08.078031","status":"completed"},"tags":[],"id":"jvI3Xmq4VaVJ","execution":{"iopub.status.busy":"2024-04-25T13:24:17.256364Z","iopub.execute_input":"2024-04-25T13:24:17.256692Z","iopub.status.idle":"2024-04-25T13:24:17.264008Z","shell.execute_reply.started":"2024-04-25T13:24:17.256663Z","shell.execute_reply":"2024-04-25T13:24:17.262950Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## **Datasets**\nThe data is labelled by the name, so we load images and label while calling '__getitem__'","metadata":{"papermill":{"duration":0.012739,"end_time":"2022-02-23T10:03:08.125181","exception":false,"start_time":"2022-02-23T10:03:08.112442","status":"completed"},"tags":[],"id":"D0ivMf-jVaVK"}},{"cell_type":"code","source":"class FoodDataset(Dataset):\n\n    def __init__(self, path=None, tfm=test_tfm, files=None):\n        super(FoodDataset, self).__init__()\n        if path:\n            self.path = path\n            self.files = sorted([os.path.join(path, x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n        if files is not None:\n            self.files = files\n        if self.files:  # 添加一个检查以确保self.files不为空\n            print(f\"One sample\", self.files[0])\n        else:\n            print(f\"No samples found in {path}\")\n        self.transform = tfm\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        fname = self.files[idx]\n        im = Image.open(fname)\n        im = self.transform(im)\n        try:\n            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n        except:\n            label = -1 # test has no label\n        return im, label\n\nclass MySubset(Subset):\n    def __init__(self, dataset, indices, tfm=test_tfm):\n        super().__init__(dataset, indices)\n        self.transform = tfm\n\n    def __getitem__(self, idx):\n        if isinstance(idx, list):\n            return self.dataset[[self.indices[i] for i in idx]]\n        self.dataset.transform = self.transform\n        return self.dataset[self.indices[idx]]\n        # do something with self.dataset[self.indices[idx]]\n        # return a modified item","metadata":{"papermill":{"duration":0.023022,"end_time":"2022-02-23T10:03:08.160912","exception":false,"start_time":"2022-02-23T10:03:08.13789","status":"completed"},"tags":[],"id":"xBdtPhKwVaVL","execution":{"iopub.status.busy":"2024-04-25T13:24:17.267291Z","iopub.execute_input":"2024-04-25T13:24:17.267601Z","iopub.status.idle":"2024-04-25T13:24:17.281276Z","shell.execute_reply.started":"2024-04-25T13:24:17.267574Z","shell.execute_reply":"2024-04-25T13:24:17.280346Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from torch import nn\n# ResNet\nclass Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n\n        self.cnn_layer1 = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1),\n            nn.BatchNorm2d(64),\n        )\n\n        self.cnn_layer2 = nn.Sequential(\n            nn.Conv2d(64, 64, 3, 1, 1),\n            nn.BatchNorm2d(64),\n        )\n\n        self.cnn_layer3 = nn.Sequential(\n            nn.Conv2d(64, 128, 3, 2, 1),\n            nn.BatchNorm2d(128),\n        )\n\n        self.cnn_layer4 = nn.Sequential(\n            nn.Conv2d(128, 128, 3, 1, 1),\n            nn.BatchNorm2d(128),\n        )\n        self.cnn_layer5 = nn.Sequential(\n            nn.Conv2d(128, 256, 3, 2, 1),\n            nn.BatchNorm2d(256),\n        )\n        self.cnn_layer6 = nn.Sequential(\n            nn.Conv2d(256, 256, 3, 1, 1),\n            nn.BatchNorm2d(256),\n        )\n        self.fc_layer = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(256* 32* 32, 256),\n            nn.ReLU(),\n            nn.Linear(256, 11)\n        )\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        # input (x): [batch_size, 3, 128, 128]\n        # output: [batch_size, 11]\n\n        # Extract features by convolutional layers.\n        x1 = self.cnn_layer1(x)\n\n        x1 = self.relu(x1)\n        \n        Residual = x1 \n        x2 = self.cnn_layer2(x1)\n        x2 = x2 + Residual\n        x2 = self.relu(x2)\n\n        x3 = self.cnn_layer3(x2)\n        \n        x3 = self.relu(x3)\n        Residual = x3 \n        \n        x4 = self.cnn_layer4(x3)\n        x4 = x4 + Residual\n        x4 = self.relu(x4)\n\n        x5 = self.cnn_layer5(x4)\n        \n        x5 = self.relu(x5)\n        Residual = x5\n        x6 = self.cnn_layer6(x5)\n        x6 = x6 + Residual\n        x6 = self.relu(x6)\n\n        # The extracted feature map must be flatten before going to fully-connected layers.\n        xout = x6.flatten(1)\n\n        # The features are transformed by fully-connected layers to obtain the final logits.\n        xout = self.fc_layer(xout)\n        return xout\n\n# VGG16\nclass VGG16(nn.Module):\n    def __init__(self):\n        super(VGG16, self).__init__()\n        # 修改vgg16的最后一层，因为原来的vgg16是1000分类，我们需要11分类\n        self.model = vgg16(weights=None)\n        num_features = self.model.classifier[6].in_features\n        self.model.classifier[6] = nn.Linear(num_features, 11)\n        self.model.num_classes = 11\n\n    def forward(self, x):\n        return self.model(x)\n    \nclass EnsembleModel(nn.Module):\n    def __init__(self, base_models):\n        super(EnsembleModel, self).__init__()\n        self.base_models = nn.ModuleList(base_models)\n        # self.classifier = nn.Linear(len(base_models) * 11, 11)\n\n    def forward(self, x):\n        outputs = [model(x) for model in self.base_models]\n        # outputs = torch.cat(outputs, dim=1)\n        # outputs = self.classifier(outputs)     \n        outputs = torch.stack(outputs)\n        outputs = torch.mean(outputs, dim=0)\n        return outputs\n","metadata":{"papermill":{"duration":0.0258,"end_time":"2022-02-23T10:03:08.199437","exception":false,"start_time":"2022-02-23T10:03:08.173637","status":"completed"},"tags":[],"id":"b_kDECOJVaVL","execution":{"iopub.status.busy":"2024-04-25T13:24:17.282464Z","iopub.execute_input":"2024-04-25T13:24:17.282744Z","iopub.status.idle":"2024-04-25T13:24:17.301348Z","shell.execute_reply.started":"2024-04-25T13:24:17.282720Z","shell.execute_reply":"2024-04-25T13:24:17.300327Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# mixup\ndef mixup_data(x, y, alpha=1.0):\n    '''Returns mixed inputs, targets, and lambda\n    Parameters\n    ----------\n    x: input data\n    y: target\n    alpha: value of alpha and beta in beta distribution \n    '''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size) # shuffle index\n    mixed_x = lam * x + (1 - lam) * x[index, :] # mixup between original image order and shuffled image order\n    y_a, y_b = y, y[index] # return target of both images order\n    \n    return mixed_x, y_a, y_b, lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    \"\"\" Updated loss for mixup.\n    Args:\n    -----\n    criterion: loss function to use, example: crossentropy loss\n    preds: predictions from network\n    y_a: original labels\n    y_b: labels of the shuffled batch\n    lam: alpha used for mixup\n    \"\"\"\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\nimport torchmetrics.functional as tmf\ndef mixup_accuracy(metric, preds, y_a, y_b, lam,num_classes,task='multiclass',):\n    \"\"\"\n    Updated metric calculation:\n    Args:\n    -----\n    metric: metric to use, example: accuracy\n    preds: predictions from network\n    y_a: original labels\n    y_b: labels of the shuffled batch\n    lam: alpha used for mixup\n    \"\"\"\n    return lam * metric(preds, y_a,num_classes=num_classes,task=task) + (1 - lam) * metric(preds, y_b,num_classes=num_classes,task=task)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-25T13:24:17.302585Z","iopub.execute_input":"2024-04-25T13:24:17.302909Z","iopub.status.idle":"2024-04-25T13:24:19.972094Z","shell.execute_reply.started":"2024-04-25T13:24:17.302879Z","shell.execute_reply":"2024-04-25T13:24:19.971249Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Configurations","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)\n\nbatch_size = 64\nn_epochs = 200\npatience = 20 # If no improvement in 'patience' epochs, early stop\nk_fold = 5\n\nmodel = Classifier().to(device)\n\nResume = False\nif Resume:\n    model.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\", map_location='cuda'))\n    \ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5) # 3e-4\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.8, patience=patience/2, threshold=0.05)\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-25T13:24:19.973383Z","iopub.execute_input":"2024-04-25T13:24:19.973744Z","iopub.status.idle":"2024-04-25T13:24:20.989153Z","shell.execute_reply.started":"2024-04-25T13:24:19.973711Z","shell.execute_reply":"2024-04-25T13:24:20.988293Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"train_dir = \"/kaggle/input/ml2022spring-hw3b/food11/training\"\nval_dir = \"/kaggle/input/ml2022spring-hw3b/food11/validation\"\ntest_dir = \"/kaggle/input/ml2022spring-hw3b/food11/test\"\n\ntrain_files = [os.path.join(train_dir, x) for x in os.listdir(train_dir) if x.endswith('.jpg')]\nval_files = [os.path.join(val_dir, x) for x in os.listdir(val_dir) if x.endswith('.jpg')]\ntest_files = [os.path.join(test_dir, x) for x in os.listdir(test_dir) if x.endswith('.jpg')]\n\ntotal_files = train_files + val_files\n","metadata":{"collapsed":false,"is_executing":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-25T13:24:20.990334Z","iopub.execute_input":"2024-04-25T13:24:20.990657Z","iopub.status.idle":"2024-04-25T13:24:22.416524Z","shell.execute_reply.started":"2024-04-25T13:24:20.990629Z","shell.execute_reply":"2024-04-25T13:24:22.415598Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# tta","metadata":{}},{"cell_type":"code","source":"def create_tta_loaders():\n    # Initialize an empty list to store the TTA test loaders\n    tta_test_loaders = []\n    for i in range(num_tta):\n        # Create a FoodDataset instance with the test folder and the train transformation\n        test_set_i = FoodDataset(tfm = train_tfm2,files=test_files)\n        tta_test_loader = DataLoader(test_set_i, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n        tta_test_loaders.append(test_loader)\n    return tta_test_loaders\n    \n\ndef tta(num_folds=5, model=None, ):\n    # Create an empty list to store the best model for each fold\n    base_models = []\n\n    # Load the best model for each fold\n    for fold in range(num_folds):\n        # Create a model instance and move it to the device (GPU or CPU)\n        model_best_i = model().to(device)\n        # Load the state dictionary of the best model for this fold from a checkpoint file\n        model_best_i.load_state_dict(torch.load(f\"models/{_exp_name}_{model_best_i.__class__.__name__}_fold{fold+1}_best.ckpt\"))\n        # Append the model to the base_models list\n        base_models.append(model_best_i)\n    # Create an ensemble model that combines the base models and move it to the device\n    model_best = EnsembleModel(base_models=base_models).to(device)\n\n    # Set the model to evaluation mode\n    model_best.eval()\n\n    # Initialize an empty list to store the prediction without test-time augmentation (TTA)\n    prediction = []\n    with torch.no_grad():\n        for data,_ in tqdm(test_loader):\n            # Get the model output on the data and move it to CPU\n            test_pred = model_best(data.to(device)).cpu().data.numpy()\n            # Add the output to the prediction list\n            prediction += test_pred.squeeze().tolist()\n    # Convert the prediction list to a numpy array\n    prediction = np.array(prediction)\n\n    # Initialize an empty list to store the predictions with TTA\n    tta_predictions = []\n    with torch.no_grad():\n        for i in range(num_tta):\n            # Initialize an empty list to store the prediction for this iteration\n            tta_prediction = []\n            for data,_ in tqdm(tta_test_loaders[i]):\n                # Get the model output on the data and move it to CPU\n                test_pred = model_best(data.to(device)).cpu().data.numpy()\n                # Add the output to the tta_prediction list\n                tta_prediction += test_pred.squeeze().tolist()\n            # Append the tta_prediction list to the tta_predictions list\n            tta_predictions.append(tta_prediction)\n\n    # Initialize a zero array with the same shape as prediction to store the total TTA predictions\n    total_tta_predictions = np.zeros_like(prediction)\n    for i in range(num_tta):\n        total_tta_predictions += tta_predictions[i]\n    # Divide the total TTA predictions by t to get the average TTA predictions\n    avg_tta_predictions = np.divide(total_tta_predictions, num_tta)\n\n    # Get the weighted average of prediction and TTA prediction\n    prediction = [0.8 * prediction[i] + 0.2 * avg_tta_predictions[i] for i in range(len(prediction))]\n    # Get the predicted labels\n    prediction = np.argmax(np.array(prediction), axis=1)\n    return prediction","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-25T13:24:22.417852Z","iopub.execute_input":"2024-04-25T13:24:22.418205Z","iopub.status.idle":"2024-04-25T13:24:22.433252Z","shell.execute_reply.started":"2024-04-25T13:24:22.418176Z","shell.execute_reply":"2024-04-25T13:24:22.432192Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# cd /kaggle/working\n#os.makedirs(\"models\")\n\n!ls","metadata":{"execution":{"iopub.status.busy":"2024-04-25T13:37:52.608031Z","iopub.execute_input":"2024-04-25T13:37:52.608964Z","iopub.status.idle":"2024-04-25T13:37:53.659704Z","shell.execute_reply.started":"2024-04-25T13:37:52.608932Z","shell.execute_reply":"2024-04-25T13:37:53.658487Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"models\tsample_log.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Stacking","metadata":{}},{"cell_type":"code","source":"def stack(dataset,test_set,n_splits,models=[],tb=False):\n    # 判断谁否有多个模型\n    if not isinstance(models,list):\n        models = [models]\n    elif not len(models):\n        raise ValueError(\"No models to stack\")\n    \n    ntrain = len(dataset)\n    ntest = len(test_set)\n    \n    G = torch.Generator()\n    G.manual_seed(myseed)\n    \n    # 记录交叉验证的模型\n    oof_dict = {}\n    # 记录交叉验证的分数\n    val_acc_dict = {}\n    \n    for i in range(len(models)):\n        \n        oof_train = np.zeros((ntrain,))\n        oof_test = np.zeros((ntest,))\n        \n        # 记录？\n        oof_test_skf = np.empty((n_splits, ntest))\n        \n        # 创建k折交叉验证\n        kf = KFold(n_splits=n_splits, shuffle=True, random_state=myseed)\n        \n        # 用于所有折的验证数据取平均\n        val_accs = []\n        \n        # 交叉验证\n        for fold,(train_idx,valid_idx) in enumerate(kf.split(dataset)):\n            \n            model = models[i]().to(device)\n            \n            print(f\"Model: {models[i].__name__},fold:{fold+1}\")\n            \n            print(f\"Train Index (len: {len(train_idx)}): {train_idx}\")\n            print(f\"Valid Index (len: {len(valid_idx)}): {valid_idx}\")\n            \n            # 每次训练要重新定义optim和scheduler\n            optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5) # 3e-4\n            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.8, patience=patience/2, threshold=0.05)     \n            \n            # Create a subset of the dataset based on the train indices\n            # 用Subset的原因：如果直接在原来上面tfm会导致验证集的tfm也被改变\n            # 所以先借用Subset分割\n            train_set = MySubset(dataset, train_idx, train_tfm2)\n            train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, generator=G)\n            # Create a subset of the dataset based on the valid indices\n            valid_set = MySubset(dataset, valid_idx, test_tfm)\n            valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)    \n            \n            stale = 0\n            best_acc = 0\n            \n            for epoch in range(n_epochs):\n                \n                # ---------- Training ----------------------------------------\n                model.train()\n                \n                train_loss = []\n                train_accs = []\n                \n                correct = 0\n                total = 0\n                \n                for imgs,labels in tqdm(train_loader):\n            \n                    # A batch consists of image data and corresponding labels.\n                    imgs, labels = imgs.to(device),labels.to(device)\n                    imgs,labels_a,labels_b,lam=mixup_data(imgs, labels)\n                    \n                    # Forward the data. (Make sure data and model are on the same device.)\n                    logits = model(imgs)\n            \n                    # Calculate the cross-entropy loss.\n                    # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n                    loss = mixup_criterion(criterion, logits, labels_a, labels_b, lam)\n            \n                    # Gradients stored in the parameters in the previous step should be cleared out first.\n                    optimizer.zero_grad()\n            \n                    # Compute the gradients for parameters.\n                    loss.backward()\n                    \n                    # Clip the gradient norms for stable training.\n                    grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n            \n                    # Update the parameters with computed gradients.\n                    optimizer.step()\n            \n                    # Compute the accuracy for current batch.\n                    _,predicted = logits.max(1)\n                    correct += (lam * predicted.eq(labels_a).sum().item()+ (1 - lam) * predicted.eq(labels_b).sum().item())\n                    total+=labels.size(0)\n                    \n                    # Record the loss and accuracy.\n                    train_loss.append(loss.item())\n            \n                train_loss = sum(train_loss) / len(train_loss)\n                train_acc = correct / total\n            \n                print(f\"Fold {fold+1}: [ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n                \n                \n                # ---------- Validation -----------------------------------------\n                # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.                \n                model.eval()\n                \n                # These are used to record information in validation.\n                valid_loss = []\n                valid_accs = []\n                \n                # Iterate the validation set by batches.\n                for batch in tqdm(valid_loader):\n\n                    # A batch consists of image data and corresponding labels.\n                    imgs, labels = batch\n                    #imgs = imgs.half()\n\n                    # We don't need gradient in validation.\n                    # Using torch.no_grad() accelerates the forward process.\n                    with torch.no_grad():\n                        logits = model(imgs.to(device))\n\n                    # We can still compute the loss (but not the gradient).\n                    loss = criterion(logits, labels.to(device))\n\n                    # Compute the accuracy for current batch.\n                    acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n                    # Record the loss and accuracy.\n                    valid_loss.append(loss.item())\n                    valid_accs.append(acc)\n                    #break\n\n                # The average loss and accuracy for entire validation set is the average of the recorded values.\n                valid_loss = sum(valid_loss) / len(valid_loss)\n                valid_acc = sum(valid_accs) / len(valid_accs)\n                \n                # Update logs\n                if valid_acc > best_acc:\n                    with open(f\"./{_exp_name}_log.txt\",\"a\"):\n                        print(f\"Fold {fold+1}: [ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n                else:\n                    with open(f\"./{_exp_name}_log.txt\",\"a\"):\n                        print(f\"Fold {fold+1}: [ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n\n\n                # Save models\n                if valid_acc > best_acc:\n                    print(f\"Best model found at epoch {epoch}, saving model\")\n                    torch.save(model.state_dict(), f\"models/{_exp_name}_{models[i].__name__}_fold{fold+1}_best.ckpt\") # only save best to prevent output memory exceed error\n                    best_acc = valid_acc\n                    stale = 0\n                else:\n                    stale += 1\n                    if stale > patience:\n                        print(f\"No improvment {patience} consecutive epochs, early stopping\")\n                        break\n                \n                # 每个训练周期之后调用\n                scheduler.step(best_acc)\n            \n            # ---------- Use the same training loop as in the previous section ----------        \n            # Append the best accuracy to the list\n            val_accs.append(best_acc)\n\n            # Out-of-Fold Predictions\n            model_best = model\n            print(f\"{_exp_name}_{models[i].__name__}_fold{fold+1}_best.ckpt\")\n            model_best.load_state_dict(torch.load(f\"/kaggle/working/models/{_exp_name}_{models[i].__name__}_fold{fold+1}_best.ckpt\"))\n            model_best.eval()\n\n            val_prediction, test_prediction = [], []\n            \n            test_prediction = tta(num_folds=NSPLITS, model = models[i])\n            \n            with torch.no_grad():\n                for data,_ in tqdm(valid_loader):\n                    val_pred = np.argmax(model_best(data.to(device)).cpu().data.numpy(), axis=1)\n                    val_prediction += val_pred.squeeze().tolist()\n                oof_train[valid_idx] = val_prediction\n\n        oof_test[:] = oof_test_skf.mean(axis=0)\n        oof_dict[f\"{models[i].__name__}_oof_train\"] = oof_train.reshape(-1, 1)\n        oof_dict[f\"{models[i].__name__}_oof_test\"] = oof_test.reshape(-1, 1)\n        \n        # Compute the average validation accuracy across all folds\n        avg_val_acc = sum(val_accs) / len(val_accs)\n        val_acc_dict[f\"{models[i].__name__}_val_accs\"] = val_accs\n        val_acc_dict[f\"{models[i].__name__}_avg_val_acc\"] = avg_val_acc\n        \n        # Print the average validation accuracy\n        print(f\"Average validation accuracy: {avg_val_acc:.4f}\")\n        \n    return oof_dict, val_acc_dict\n\ndataset = FoodDataset(tfm=test_tfm,files=total_files)\n\ntest_set = FoodDataset(tfm=test_tfm,files=test_files)\ntest_loader = DataLoader(dataset,batch_size = batch_size,shuffle=False,num_workers=0,pin_memory=True)\n\nprint(\"begin----\")\nNSPLITS = 5\n\nnum_tta = 5\n\ntta_test_loaders = create_tta_loaders()\nprint(\"--\")\nmodels = [Classifier,VGG16]\n                \noof_dict,val_acc_dict = stack(dataset,test_set,NSPLITS,models=models)","metadata":{"collapsed":false,"is_executing":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-25T13:37:58.942668Z","iopub.execute_input":"2024-04-25T13:37:58.943086Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"One sample /kaggle/input/ml2022spring-hw3b/food11/training/8_248.jpg\nOne sample /kaggle/input/ml2022spring-hw3b/food11/test/0664.jpg\nbegin----\nOne sample /kaggle/input/ml2022spring-hw3b/food11/test/0664.jpg\nOne sample /kaggle/input/ml2022spring-hw3b/food11/test/0664.jpg\nOne sample /kaggle/input/ml2022spring-hw3b/food11/test/0664.jpg\nOne sample /kaggle/input/ml2022spring-hw3b/food11/test/0664.jpg\nOne sample /kaggle/input/ml2022spring-hw3b/food11/test/0664.jpg\n--\nModel: Classifier,fold:1\nTrain Index (len: 10636): [    0     2     3 ... 13293 13294 13295]\nValid Index (len: 2660): [    1     5     7 ... 13268 13277 13292]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/167 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bd7b9f6225e4f5587b7615a37a845e7"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-04-22T07:37:43.830660400Z","start_time":"2024-04-22T07:37:42.826736900Z"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cross validation 交叉验证\nYou can implement cross validation entirely using the cross_val_score in sklearn.model_selection, but I'll show you another way to implement it here.","metadata":{}},{"cell_type":"markdown","source":"# 保存模型","metadata":{}},{"cell_type":"code","source":"orch.save(model.state_dict(), \"Classifier1.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T13:28:37.776324Z","iopub.status.idle":"2024-04-25T13:28:37.776664Z","shell.execute_reply.started":"2024-04-25T13:28:37.776502Z","shell.execute_reply":"2024-04-25T13:28:37.776517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 加载测试集","metadata":{}},{"cell_type":"code","source":"test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)","metadata":{"papermill":{"duration":0.493644,"end_time":"2022-02-23T19:10:19.985992","exception":false,"start_time":"2022-02-23T19:10:19.492348","status":"completed"},"tags":[],"id":"B9QNdHIXVaVP","outputId":"02fc4afa-dd85-4adb-bc28-37cafabe07cd","execution":{"iopub.status.busy":"2024-04-25T13:28:37.778480Z","iopub.status.idle":"2024-04-25T13:28:37.778822Z","shell.execute_reply.started":"2024-04-25T13:28:37.778659Z","shell.execute_reply":"2024-04-25T13:28:37.778674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing and generate prediction CSV","metadata":{"papermill":{"duration":0.498773,"end_time":"2022-02-23T19:10:20.961802","exception":false,"start_time":"2022-02-23T19:10:20.463029","status":"completed"},"tags":[],"id":"G31uyjpvVaVP"}},{"cell_type":"code","source":"!cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-04-25T13:28:37.780095Z","iopub.status.idle":"2024-04-25T13:28:37.780398Z","shell.execute_reply.started":"2024-04-25T13:28:37.780249Z","shell.execute_reply":"2024-04-25T13:28:37.780262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_best = Classifier().to(device)\nmodel_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\nmodel_best.eval()\nprediction = []\nwith torch.no_grad():\n    for data,_ in test_loader:\n        test_pred = model_best(data.to(device))\n        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n        prediction += test_label.squeeze().tolist()","metadata":{"papermill":{"duration":49.157727,"end_time":"2022-02-23T19:11:10.61523","exception":false,"start_time":"2022-02-23T19:10:21.457503","status":"completed"},"tags":[],"id":"bpLtxx5FVaVP","execution":{"iopub.status.busy":"2024-04-25T13:28:37.781306Z","iopub.status.idle":"2024-04-25T13:28:37.781597Z","shell.execute_reply.started":"2024-04-25T13:28:37.781450Z","shell.execute_reply":"2024-04-25T13:28:37.781463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create test csv\ndef pad4(i):\n    return \"0\"*(4-len(str(i)))+str(i)\ndf = pd.DataFrame()\ndf[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\ndf[\"Category\"] = prediction\ndf.to_csv(\"submission.csv\",index = False)","metadata":{"papermill":{"duration":0.554276,"end_time":"2022-02-23T19:11:11.870035","exception":false,"start_time":"2022-02-23T19:11:11.315759","status":"completed"},"tags":[],"id":"fKupB3VUVaVQ","execution":{"iopub.status.busy":"2024-04-25T13:28:37.782762Z","iopub.status.idle":"2024-04-25T13:28:37.783111Z","shell.execute_reply.started":"2024-04-25T13:28:37.782918Z","shell.execute_reply":"2024-04-25T13:28:37.782939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Q1. Augmentation Implementation\n## Implement augmentation by finishing train_tfm in the code with image size of your choice.\n## Directly copy the following block and paste it on GradeScope after you finish the code\n### Your train_tfm must be capable of producing 5+ different results when given an identical image multiple times.\n### Your  train_tfm in the report can be different from train_tfm in your training code.\n","metadata":{"id":"Ivk0hrE-V8Cu"}},{"cell_type":"code","source":"train_tfm = transforms.Compose([\n    # Resize the image into a fixed shape (height = width = 128)\n    transforms.Resize((128, 128)),\n    # You need to add some transforms here.\n    transforms.ToTensor(),\n])","metadata":{"id":"GSfKNo42WjKm","execution":{"iopub.status.busy":"2024-04-25T13:28:37.784216Z","iopub.status.idle":"2024-04-25T13:28:37.784677Z","shell.execute_reply.started":"2024-04-25T13:28:37.784433Z","shell.execute_reply":"2024-04-25T13:28:37.784452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Q2. Residual Implementation\n![](https://i.imgur.com/GYsq1Ap.png)\n## Directly copy the following block and paste it on GradeScope after you finish the code\n","metadata":{"id":"3HemRgZ6WwRM"}},{"cell_type":"code","source":"from torch import nn\nclass Residual_Network(nn.Module):\n    def __init__(self):\n        super(Residual_Network, self).__init__()\n\n        self.cnn_layer1 = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1),\n            nn.BatchNorm2d(64),\n        )\n\n        self.cnn_layer2 = nn.Sequential(\n            nn.Conv2d(64, 64, 3, 1, 1),\n            nn.BatchNorm2d(64),\n        )\n\n        self.cnn_layer3 = nn.Sequential(\n            nn.Conv2d(64, 128, 3, 2, 1),\n            nn.BatchNorm2d(128),\n        )\n\n        self.cnn_layer4 = nn.Sequential(\n            nn.Conv2d(128, 128, 3, 1, 1),\n            nn.BatchNorm2d(128),\n        )\n        self.cnn_layer5 = nn.Sequential(\n            nn.Conv2d(128, 256, 3, 2, 1),\n            nn.BatchNorm2d(256),\n        )\n        self.cnn_layer6 = nn.Sequential(\n            nn.Conv2d(256, 256, 3, 1, 1),\n            nn.BatchNorm2d(256),\n        )\n        self.fc_layer = nn.Sequential(\n            nn.Linear(256* 32* 32, 256),\n            nn.ReLU(),\n            nn.Linear(256, 11)\n        )\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        # input (x): [batch_size, 3, 128, 128]\n        # output: [batch_size, 11]\n\n        # Extract features by convolutional layers.\n        x1 = self.cnn_layer1(x)\n\n        x1 = self.relu(x1)\n        \n        Residual = x1 \n        x2 = self.cnn_layer2(x1)\n        x2 = x2 + Residual\n        x2 = self.relu(x2)\n\n        x3 = self.cnn_layer3(x2)\n        \n        x3 = self.relu(x3)\n        Residual = x3 \n        \n        x4 = self.cnn_layer4(x3)\n        x4 = x4 + Residual\n        x4 = self.relu(x4)\n\n        x5 = self.cnn_layer5(x4)\n        \n        x5 = self.relu(x5)\n        Residual = x5\n        x6 = self.cnn_layer6(x5)\n        x6 = x6 + Residual\n        x6 = self.relu(x6)\n\n        # The extracted feature map must be flatten before going to fully-connected layers.\n        xout = x6.flatten(1)\n\n        # The features are transformed by fully-connected layers to obtain the final logits.\n        xout = self.fc_layer(xout)\n        return xout","metadata":{"id":"Q4OK9kRaWuiV","execution":{"iopub.status.busy":"2024-04-25T13:28:37.785697Z","iopub.status.idle":"2024-04-25T13:28:37.786155Z","shell.execute_reply.started":"2024-04-25T13:28:37.785905Z","shell.execute_reply":"2024-04-25T13:28:37.785923Z"},"trusted":true},"execution_count":null,"outputs":[]}]}